{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#    Music Generation by Restricted Boltzmann Machine (RBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the python libraries that we need for the Music Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheta\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import msgpack\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tqdm import tqdm\n",
    "import midi_manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Dataset to the network to train the machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_songs(path):\n",
    "    files = glob.glob('{}/*.mid*'.format(path))\n",
    "    songs = []\n",
    "    for f in tqdm(files):\n",
    "        try:\n",
    "            song = np.array(midi_manipulation.midiToNoteStateMatrix(f))\n",
    "            if np.array(song).shape[0] > 50:\n",
    "                songs.append(song)\n",
    "        except Exception as e:\n",
    "            raise e           \n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 126/126 [00:03<00:00, 40.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 songs processed\n"
     ]
    }
   ],
   "source": [
    "songs = get_songs('Pop_Music_Midi') #These songs have already been converted from midi to msgpack\n",
    "print (\"{} songs processed\".format(len(songs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "\n",
    "# The hyperparameters of our models are initilised as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# This gives us the lowest note on the piano roll\n",
    "lowest_note = midi_manipulation.lowerBound\n",
    "print(lowest_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "# This gives us the highest note on the piano roll\n",
    "highest_note = midi_manipulation.upperBound\n",
    "print(highest_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "# The note range of the piano roll will be given by the difference between upperBound and the lowerBound\n",
    "note_range = highest_note - lowest_note\n",
    "print(note_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_timesteps is the number of timesteps that we will create at a time\n",
    "num_timesteps  = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2340\n"
     ]
    }
   ],
   "source": [
    "# Initialising the size of visible layer\n",
    "n_visible      = 2 * note_range * num_timesteps\n",
    "print(n_visible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the size of hidden layer\n",
    "n_hidden = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of training epochs that we are going to run. For each epoch we go through the entire data set.\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of training examples that we are going to send through the RBM at a time. \n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#The learning rate of our model\n",
    "lr = tf.constant(0.005, tf.float32)\n",
    "print(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables that we are going to use for the model\n",
    "# lets initialize the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"x:0\", shape=(?, 2340), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# x is the placeholder variable that holds our data\n",
    "x  = tf.placeholder(tf.float32, [None, n_visible], name=\"x\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'W:0' shape=(2340, 50) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "#W is the weight matrix that stores the edge weights\n",
    "W  = tf.Variable(tf.random_normal([n_visible, n_hidden], 0.01), name=\"W\")\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(1, 50) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "#bh is the bias vector for the hidden layer\n",
    "bh = tf.Variable(tf.zeros([1, n_hidden],  tf.float32, name=\"bh\"))\n",
    "print(bh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_1:0' shape=(1, 2340) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "#bv is the bias vector for the visible layer\n",
    "bv = tf.Variable(tf.zeros([1, n_visible],  tf.float32, name=\"bv\"))\n",
    "print(bv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample function lets us easily sample from a vector of probabilities\n",
    "#Takes in a vector of probabilities, and returns a random vector of 0s and 1s sampled from the input vector\n",
    "def sample(probs):\n",
    "    return tf.floor(probs + tf.random_uniform(tf.shape(probs), 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function runs the gibbs chain. We will call this function in two places:\n",
    "#    - When we define the training update step\n",
    "#    - When we sample our music segments from the trained RBM\n",
    "def gibbs_sample(k):\n",
    "    #Runs a k-step gibbs chain to sample from the probability distribution of the RBM defined by W, bh, bv\n",
    "    def gibbs_step(count, k, xk):\n",
    "        #Runs a single gibbs step. The visible values are initialized to xk\n",
    "        hk = sample(tf.sigmoid(tf.matmul(xk, W) + bh)) #Propagate the visible values to sample the hidden values\n",
    "        xk = sample(tf.sigmoid(tf.matmul(hk, tf.transpose(W)) + bv)) #Propagate the hidden values to sample the visible values\n",
    "        return count+1, k, xk\n",
    "    #Run gibbs steps for k iterations\n",
    "    ct = tf.constant(0) #counter\n",
    "    [_, _, x_sample] = control_flow_ops.while_loop(lambda count, num_iter, *args: count < num_iter,\n",
    "                                         gibbs_step, [ct, tf.constant(k), x])\n",
    "    #This is not strictly necessary in this implementation, but if you want to adapt this code to use one of TensorFlow's\n",
    "    #optimizers, you need this in order to stop tensorflow from propagating gradients back through the gibbs step\n",
    "    x_sample = tf.stop_gradient(x_sample) \n",
    "    return x_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training Update Code\n",
    "# Now we implement the contrastive divergence algorithm. First, we get the samples of x and h from the probability distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"StopGradient:0\", shape=(?, 2340), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#The sample of x\n",
    "x_sample = gibbs_sample(1)\n",
    "print(x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Floor:0\", shape=(?, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#The sample of the hidden nodes, starting from the visible state of x\n",
    "h = sample(tf.sigmoid(tf.matmul(x, W) + bh))\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Floor_1:0\", shape=(?, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#The sample of the hidden nodes, starting from the visible state of x_sample\n",
    "h_sample = sample(tf.sigmoid(tf.matmul(x_sample, W) + bh)) \n",
    "print(h_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we update the values of W, bh, and bv, based on the difference between the samples that we drew and the original values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Cast:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "size_bt = tf.cast(tf.shape(x)[0], tf.float32)\n",
    "print(size_bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mul:0\", shape=(2340, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "W_adder  = tf.multiply(lr/size_bt, tf.subtract(tf.matmul(tf.transpose(x), h), tf.matmul(tf.transpose(x_sample), h_sample)))\n",
    "print(W_adder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mul_1:0\", shape=(1, 2340), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "bv_adder = tf.multiply(lr/size_bt, tf.reduce_sum(tf.subtract(x, x_sample), 0, True))\n",
    "print(bv_adder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mul_2:0\", shape=(1, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "bh_adder = tf.multiply(lr/size_bt, tf.reduce_sum(tf.subtract(h, h_sample), 0, True))\n",
    "print(bh_adder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'AssignAdd:0' shape=(2340, 50) dtype=float32_ref>, <tf.Tensor 'AssignAdd_1:0' shape=(1, 2340) dtype=float32_ref>, <tf.Tensor 'AssignAdd_2:0' shape=(1, 50) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "#When we do sess.run(updt), TensorFlow will run all 3 update steps\n",
    "updt = [W.assign_add(W_adder), bv.assign_add(bv_adder), bh.assign_add(bh_adder)]\n",
    "print(updt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the tensorflow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:44<00:00,  4.46it/s]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #First, we train the model\n",
    "    #initialize the variables of the model\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    #Run through all of the training data num_epochs times\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for song in songs:\n",
    "            \n",
    "            #The songs are stored in a time x notes format. The size of each song is timesteps_in_song x 2*note_range\n",
    "            #Here we reshape the songs so that each training example is a vector with num_timesteps x 2*note_range elements\n",
    "            \n",
    "            song = np.array(song)\n",
    "            song = song[:int(np.floor(song.shape[0]//num_timesteps)*num_timesteps)]\n",
    "            song = np.reshape(song, [song.shape[0]//num_timesteps, song.shape[1]*num_timesteps])\n",
    "            \n",
    "            #Train the RBM on batch_size examples at a time\n",
    "            \n",
    "            for i in range(1, len(song), batch_size): \n",
    "                tr_x = song[i:i+batch_size]\n",
    "                sess.run(updt, feed_dict={x: tr_x})\n",
    "\n",
    "    #Now the model is fully trained, so let's make some music! \n",
    "    #Run a gibbs chain where the visible nodes are initialized to 0\n",
    "    \n",
    "    sample = gibbs_sample(1).eval(session=sess, feed_dict={x: np.zeros((200, n_visible))})\n",
    "    for i in range(sample.shape[0]):\n",
    "        if not any(sample[i,:]):\n",
    "            continue\n",
    "            \n",
    "        #Here we reshape the vector to be time x notes, and then save the vector as a midi file\n",
    "        \n",
    "        Music = np.reshape(sample[i,:], (num_timesteps, 2*note_range))\n",
    "        midi_manipulation.noteStateMatrixToMidi(Music, \"Output//generated_chord_Music_{}\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** the generated chord music is now placed in the output folder but these are in small snippets. So we merge these files to one big music file which finalises the MUSIC GENERATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the libraries which are needed to merge the generated chords to one final music midi file are already imported to this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    files = glob.glob('Output//generated*.mid*')\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Output\\\\generated_chord_Music_0.mid', 'Output\\\\generated_chord_Music_1.mid', 'Output\\\\generated_chord_Music_10.mid', 'Output\\\\generated_chord_Music_100.mid', 'Output\\\\generated_chord_Music_101.mid', 'Output\\\\generated_chord_Music_102.mid', 'Output\\\\generated_chord_Music_103.mid', 'Output\\\\generated_chord_Music_104.mid', 'Output\\\\generated_chord_Music_105.mid', 'Output\\\\generated_chord_Music_106.mid', 'Output\\\\generated_chord_Music_107.mid', 'Output\\\\generated_chord_Music_108.mid', 'Output\\\\generated_chord_Music_109.mid', 'Output\\\\generated_chord_Music_11.mid', 'Output\\\\generated_chord_Music_110.mid', 'Output\\\\generated_chord_Music_111.mid', 'Output\\\\generated_chord_Music_112.mid', 'Output\\\\generated_chord_Music_113.mid', 'Output\\\\generated_chord_Music_114.mid', 'Output\\\\generated_chord_Music_115.mid', 'Output\\\\generated_chord_Music_116.mid', 'Output\\\\generated_chord_Music_117.mid', 'Output\\\\generated_chord_Music_118.mid', 'Output\\\\generated_chord_Music_119.mid', 'Output\\\\generated_chord_Music_12.mid', 'Output\\\\generated_chord_Music_120.mid', 'Output\\\\generated_chord_Music_121.mid', 'Output\\\\generated_chord_Music_122.mid', 'Output\\\\generated_chord_Music_123.mid', 'Output\\\\generated_chord_Music_124.mid', 'Output\\\\generated_chord_Music_125.mid', 'Output\\\\generated_chord_Music_126.mid', 'Output\\\\generated_chord_Music_127.mid', 'Output\\\\generated_chord_Music_128.mid', 'Output\\\\generated_chord_Music_129.mid', 'Output\\\\generated_chord_Music_13.mid', 'Output\\\\generated_chord_Music_130.mid', 'Output\\\\generated_chord_Music_131.mid', 'Output\\\\generated_chord_Music_132.mid', 'Output\\\\generated_chord_Music_133.mid', 'Output\\\\generated_chord_Music_134.mid', 'Output\\\\generated_chord_Music_135.mid', 'Output\\\\generated_chord_Music_136.mid', 'Output\\\\generated_chord_Music_137.mid', 'Output\\\\generated_chord_Music_138.mid', 'Output\\\\generated_chord_Music_139.mid', 'Output\\\\generated_chord_Music_14.mid', 'Output\\\\generated_chord_Music_140.mid', 'Output\\\\generated_chord_Music_141.mid', 'Output\\\\generated_chord_Music_142.mid', 'Output\\\\generated_chord_Music_143.mid', 'Output\\\\generated_chord_Music_144.mid', 'Output\\\\generated_chord_Music_145.mid', 'Output\\\\generated_chord_Music_146.mid', 'Output\\\\generated_chord_Music_147.mid', 'Output\\\\generated_chord_Music_148.mid', 'Output\\\\generated_chord_Music_149.mid', 'Output\\\\generated_chord_Music_15.mid', 'Output\\\\generated_chord_Music_150.mid', 'Output\\\\generated_chord_Music_151.mid', 'Output\\\\generated_chord_Music_152.mid', 'Output\\\\generated_chord_Music_153.mid', 'Output\\\\generated_chord_Music_154.mid', 'Output\\\\generated_chord_Music_155.mid', 'Output\\\\generated_chord_Music_156.mid', 'Output\\\\generated_chord_Music_157.mid', 'Output\\\\generated_chord_Music_158.mid', 'Output\\\\generated_chord_Music_159.mid', 'Output\\\\generated_chord_Music_16.mid', 'Output\\\\generated_chord_Music_160.mid', 'Output\\\\generated_chord_Music_161.mid', 'Output\\\\generated_chord_Music_162.mid', 'Output\\\\generated_chord_Music_163.mid', 'Output\\\\generated_chord_Music_164.mid', 'Output\\\\generated_chord_Music_165.mid', 'Output\\\\generated_chord_Music_166.mid', 'Output\\\\generated_chord_Music_167.mid', 'Output\\\\generated_chord_Music_168.mid', 'Output\\\\generated_chord_Music_169.mid', 'Output\\\\generated_chord_Music_17.mid', 'Output\\\\generated_chord_Music_170.mid', 'Output\\\\generated_chord_Music_171.mid', 'Output\\\\generated_chord_Music_172.mid', 'Output\\\\generated_chord_Music_173.mid', 'Output\\\\generated_chord_Music_174.mid', 'Output\\\\generated_chord_Music_175.mid', 'Output\\\\generated_chord_Music_176.mid', 'Output\\\\generated_chord_Music_177.mid', 'Output\\\\generated_chord_Music_178.mid', 'Output\\\\generated_chord_Music_179.mid', 'Output\\\\generated_chord_Music_18.mid', 'Output\\\\generated_chord_Music_180.mid', 'Output\\\\generated_chord_Music_181.mid', 'Output\\\\generated_chord_Music_182.mid', 'Output\\\\generated_chord_Music_183.mid', 'Output\\\\generated_chord_Music_184.mid', 'Output\\\\generated_chord_Music_185.mid', 'Output\\\\generated_chord_Music_186.mid', 'Output\\\\generated_chord_Music_187.mid', 'Output\\\\generated_chord_Music_188.mid', 'Output\\\\generated_chord_Music_189.mid', 'Output\\\\generated_chord_Music_19.mid', 'Output\\\\generated_chord_Music_190.mid', 'Output\\\\generated_chord_Music_191.mid', 'Output\\\\generated_chord_Music_192.mid', 'Output\\\\generated_chord_Music_193.mid', 'Output\\\\generated_chord_Music_194.mid', 'Output\\\\generated_chord_Music_195.mid', 'Output\\\\generated_chord_Music_196.mid', 'Output\\\\generated_chord_Music_197.mid', 'Output\\\\generated_chord_Music_198.mid', 'Output\\\\generated_chord_Music_199.mid', 'Output\\\\generated_chord_Music_2.mid', 'Output\\\\generated_chord_Music_20.mid', 'Output\\\\generated_chord_Music_21.mid', 'Output\\\\generated_chord_Music_22.mid', 'Output\\\\generated_chord_Music_23.mid', 'Output\\\\generated_chord_Music_24.mid', 'Output\\\\generated_chord_Music_25.mid', 'Output\\\\generated_chord_Music_26.mid', 'Output\\\\generated_chord_Music_27.mid', 'Output\\\\generated_chord_Music_28.mid', 'Output\\\\generated_chord_Music_29.mid', 'Output\\\\generated_chord_Music_3.mid', 'Output\\\\generated_chord_Music_30.mid', 'Output\\\\generated_chord_Music_31.mid', 'Output\\\\generated_chord_Music_32.mid', 'Output\\\\generated_chord_Music_33.mid', 'Output\\\\generated_chord_Music_34.mid', 'Output\\\\generated_chord_Music_35.mid', 'Output\\\\generated_chord_Music_36.mid', 'Output\\\\generated_chord_Music_37.mid', 'Output\\\\generated_chord_Music_38.mid', 'Output\\\\generated_chord_Music_39.mid', 'Output\\\\generated_chord_Music_4.mid', 'Output\\\\generated_chord_Music_40.mid', 'Output\\\\generated_chord_Music_41.mid', 'Output\\\\generated_chord_Music_42.mid', 'Output\\\\generated_chord_Music_43.mid', 'Output\\\\generated_chord_Music_44.mid', 'Output\\\\generated_chord_Music_45.mid', 'Output\\\\generated_chord_Music_46.mid', 'Output\\\\generated_chord_Music_47.mid', 'Output\\\\generated_chord_Music_48.mid', 'Output\\\\generated_chord_Music_49.mid', 'Output\\\\generated_chord_Music_5.mid', 'Output\\\\generated_chord_Music_50.mid', 'Output\\\\generated_chord_Music_51.mid', 'Output\\\\generated_chord_Music_52.mid', 'Output\\\\generated_chord_Music_53.mid', 'Output\\\\generated_chord_Music_54.mid', 'Output\\\\generated_chord_Music_55.mid', 'Output\\\\generated_chord_Music_56.mid', 'Output\\\\generated_chord_Music_57.mid', 'Output\\\\generated_chord_Music_58.mid', 'Output\\\\generated_chord_Music_59.mid', 'Output\\\\generated_chord_Music_6.mid', 'Output\\\\generated_chord_Music_60.mid', 'Output\\\\generated_chord_Music_61.mid', 'Output\\\\generated_chord_Music_62.mid', 'Output\\\\generated_chord_Music_63.mid', 'Output\\\\generated_chord_Music_64.mid', 'Output\\\\generated_chord_Music_65.mid', 'Output\\\\generated_chord_Music_66.mid', 'Output\\\\generated_chord_Music_67.mid', 'Output\\\\generated_chord_Music_68.mid', 'Output\\\\generated_chord_Music_69.mid', 'Output\\\\generated_chord_Music_7.mid', 'Output\\\\generated_chord_Music_70.mid', 'Output\\\\generated_chord_Music_71.mid', 'Output\\\\generated_chord_Music_72.mid', 'Output\\\\generated_chord_Music_73.mid', 'Output\\\\generated_chord_Music_74.mid', 'Output\\\\generated_chord_Music_75.mid', 'Output\\\\generated_chord_Music_76.mid', 'Output\\\\generated_chord_Music_77.mid', 'Output\\\\generated_chord_Music_78.mid', 'Output\\\\generated_chord_Music_79.mid', 'Output\\\\generated_chord_Music_8.mid', 'Output\\\\generated_chord_Music_80.mid', 'Output\\\\generated_chord_Music_81.mid', 'Output\\\\generated_chord_Music_82.mid', 'Output\\\\generated_chord_Music_83.mid', 'Output\\\\generated_chord_Music_84.mid', 'Output\\\\generated_chord_Music_85.mid', 'Output\\\\generated_chord_Music_86.mid', 'Output\\\\generated_chord_Music_87.mid', 'Output\\\\generated_chord_Music_88.mid', 'Output\\\\generated_chord_Music_89.mid', 'Output\\\\generated_chord_Music_9.mid', 'Output\\\\generated_chord_Music_90.mid', 'Output\\\\generated_chord_Music_91.mid', 'Output\\\\generated_chord_Music_92.mid', 'Output\\\\generated_chord_Music_93.mid', 'Output\\\\generated_chord_Music_94.mid', 'Output\\\\generated_chord_Music_95.mid', 'Output\\\\generated_chord_Music_96.mid', 'Output\\\\generated_chord_Music_97.mid', 'Output\\\\generated_chord_Music_98.mid', 'Output\\\\generated_chord_Music_99.mid']\n"
     ]
    }
   ],
   "source": [
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = np.zeros((0,156))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the generated chord using numpy's concatenation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 798.86it/s]\n"
     ]
    }
   ],
   "source": [
    "for f in tqdm(files):\n",
    "    try:\n",
    "        song = np.array(midi_manipulation.midiToNoteStateMatrix(f))\n",
    "\n",
    "        if np.array(song).shape[0] < 5:\n",
    "            songs = np.concatenate((songs,song))\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samlpes merging ...\n",
      "(200, 156)\n"
     ]
    }
   ],
   "source": [
    "print (\"samlpes merging ...\")\n",
    "print (np.shape(songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_manipulation.noteStateMatrixToMidi(songs, \"Output//Final_Generated_Midi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
